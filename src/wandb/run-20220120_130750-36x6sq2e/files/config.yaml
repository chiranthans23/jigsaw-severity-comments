wandb_version: 1

T_max:
  desc: null
  value: 500
_wandb:
  desc: null
  value:
    cli_version: 0.12.9
    framework: huggingface
    huggingface_version: 4.15.0
    is_jupyter_run: false
    is_kaggle_kernel: true
    m:
    - 1: trainer/global_step
      6:
      - 3
    - 1: train_loss
      5: 1
      6:
      - 1
    - 1: epoch
      5: 1
      6:
      - 1
    - 1: val_loss
      5: 1
      6:
      - 1
    python_version: 3.7.10
    start_time: 1642684070
    t:
      1:
      - 1
      - 9
      - 11
      2:
      - 1
      - 9
      - 11
      3:
      - 7
      - 16
      4: 3.7.10
      5: 0.12.9
      6: 4.15.0
      8:
      - 2
      - 5
_wandb_kernel:
  desc: null
  value: neuracort
checkpoint_directory_path:
  desc: null
  value: ../models/checkpoints
competition:
  desc: null
  value: Jigsaw
device:
  desc: null
  value: cuda
epochs:
  desc: null
  value: 2
infra:
  desc: null
  value: Kaggle
learning_rate:
  desc: null
  value: 0.0001
margin:
  desc: null
  value: 0.5
max_length:
  desc: null
  value: 128
min_lr:
  desc: null
  value: 1.0e-06
model_name:
  desc: null
  value: ../model/hateBERT
n_accumulate:
  desc: null
  value: 1
n_fold:
  desc: null
  value: 5
num_classes:
  desc: null
  value: 1
num_workers:
  desc: null
  value: 2
scheduler:
  desc: null
  value: CosineAnnealingLR
seed:
  desc: null
  value: 42
tokenizer:
  desc: null
  value: 'PreTrainedTokenizerFast(name_or_path=''../model/hateBERT'', vocab_size=30522,
    model_max_len=512, is_fast=True, padding_side=''right'', special_tokens={''unk_token'':
    ''[UNK]'', ''sep_token'': ''[SEP]'', ''pad_token'': ''[PAD]'', ''cls_token'':
    ''[CLS]'', ''mask_token'': ''[MASK]''})'
train_batch_size:
  desc: null
  value: 32
train_file_path:
  desc: null
  value: ../input/folds/train_folds_5.csv
valid_batch_size:
  desc: null
  value: 64
wandb:
  desc: null
  value: true
weight_decay:
  desc: null
  value: 1.0e-06
