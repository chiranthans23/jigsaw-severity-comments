{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confidential-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import string\n",
    "\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy.lang.en import English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "miniature-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_text(text):\n",
    "    emoticons = [\n",
    "        \":-)\",\n",
    "        \":)\",\n",
    "        \"(:\",\n",
    "        \"(-:\",\n",
    "        \":))\",\n",
    "        \"((:\",\n",
    "        \":-D\",\n",
    "        \":D\",\n",
    "        \"X-D\",\n",
    "        \"XD\",\n",
    "        \"xD\",\n",
    "        \"xD\",\n",
    "        \"<3\",\n",
    "        \"</3\",\n",
    "        \":\\*\",\n",
    "        \";-)\",\n",
    "        \";)\",\n",
    "        \";-D\",\n",
    "        \";D\",\n",
    "        \"(;\",\n",
    "        \"(-;\",\n",
    "        \":-(\",\n",
    "        \":(\",\n",
    "        \"(:\",\n",
    "        \"(-:\",\n",
    "        \":,(\",\n",
    "        \":'(\",\n",
    "        ':\"(',\n",
    "        \":((\",\n",
    "        \":D\",\n",
    "        \"=D\",\n",
    "        \"=)\",\n",
    "        \"(=\",\n",
    "        \"=(\",\n",
    "        \")=\",\n",
    "        \"=-O\",\n",
    "        \"O-=\",\n",
    "        \":o\",\n",
    "        \"o:\",\n",
    "        \"O:\",\n",
    "        \"O:\",\n",
    "        \":-o\",\n",
    "        \"o-:\",\n",
    "        \":P\",\n",
    "        \":p\",\n",
    "        \":S\",\n",
    "        \":s\",\n",
    "        \":@\",\n",
    "        \":>\",\n",
    "        \":<\",\n",
    "        \"^_^\",\n",
    "        \"^.^\",\n",
    "        \">.>\",\n",
    "        \"T_T\",\n",
    "        \"T-T\",\n",
    "        \"-.-\",\n",
    "        \"*.*\",\n",
    "        \"~.~\",\n",
    "        \":*\",\n",
    "        \":-*\",\n",
    "        \"xP\",\n",
    "        \"XP\",\n",
    "        \"XP\",\n",
    "        \"Xp\",\n",
    "        \":-|\",\n",
    "        \":->\",\n",
    "        \":-<\",\n",
    "        \"$_$\",\n",
    "        \"8-)\",\n",
    "        \":-P\",\n",
    "        \":-p\",\n",
    "        \"=P\",\n",
    "        \"=p\",\n",
    "        \":*)\",\n",
    "        \"*-*\",\n",
    "        \"B-)\",\n",
    "        \"O.o\",\n",
    "        \"X-(\",\n",
    "        \")-X\",\n",
    "    ]\n",
    "    text = text.replace(\".\", \" \").lower()\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n",
    "    users = re.findall(\"[@]\\w+\", text)\n",
    "    for user in users:\n",
    "        text = text.replace(user, \"<user>\")\n",
    "    urls = re.findall(r\"(https?://[^\\s]+)\", text)\n",
    "    if len(urls) != 0:\n",
    "        for url in urls:\n",
    "            text = text.replace(url, \"<url >\")\n",
    "    for emo in text:\n",
    "        if emo in emoji.UNICODE_EMOJI:\n",
    "            text = text.replace(emo, \"<emoticon >\")\n",
    "    for emo in emoticons:\n",
    "        text = text.replace(emo, \"<emoticon >\")\n",
    "    numbers = re.findall(\"[0-9]+\", text)\n",
    "    for number in numbers:\n",
    "        text = text.replace(number, \"<number >\")\n",
    "    text = text.replace(\"#\", \"<hashtag >\")\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \", text)\n",
    "    text = \"\".join(l for l in text if l not in string.punctuation)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continent-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "tok = English()\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token.text for token in tok.tokenizer(pre_process_text(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lonely-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../input/vocab2index.txt\", \"r\")\n",
    "contents = file.read()\n",
    "vocab2index = ast.literal_eval(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "boring-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return \" \".join(map(str, encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "painted-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "df1, df2 = df.copy(deep=True), df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "better-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"encoded\"] = df1[\"more_toxic\"].apply(lambda x: encode_sentence(x, vocab2index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seasonal-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"encoded\"] = df2[\"less_toxic\"].apply(lambda x: encode_sentence(x, vocab2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immune-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[['encoded']]\n",
    "df2=df2[['encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ordinary-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('../input/jigsaw-toxic-severity-rating/validation_data_more_toxic.csv')\n",
    "df2.to_csv('../input/jigsaw-toxic-severity-rating/validation_data_less_toxic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-ozone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
